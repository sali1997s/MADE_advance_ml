{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework_04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закодировано предложение целиком, вместе с пробелами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем файл War and Peace ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_hw4/WarAndPeace.txt', 'r', encoding=\"utf8\") as file:\n",
    "    data_ru = file.readlines()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем частоты символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenz(text):\n",
    "    letter_ru = {}\n",
    "    for letter in text.lower():\n",
    "        if letter in letter_ru.keys():\n",
    "            letter_ru[letter] += 1\n",
    "        else:\n",
    "            letter_ru[letter] = 1\n",
    "    return letter_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_ru = [u for u, _ in sorted(tokenz(''.join(data_ru)).items(), key = lambda x: x[1], reverse = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем случайную перестановку символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_ru = np.random.permutation(letter_ru)\n",
    "\n",
    "encoding_ru = {letter_ru[i]:permutation_ru[i] for i in range(len(letter_ru))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовые данные - 3 предложение Анны Коренниной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_hw4/AnnaKarenina.txt', 'r', encoding=\"utf8\") as file:\n",
    "    test = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "test_ru = test[3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_ru = ''.join([encoding_ru[test_ru[i]] for i in range(len(test_ru))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'«анна каренина», один из самых знаменитых романов льва толстого, начинается ставшей афоризмом фразой: «все счастливые семьи похожи друг на друга, каждая несчастливая семья несчастлива по-своему». это книга о вечных ценностях: о любви, о вере, о семье, о человеческом достоинстве.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bц--цé6цяq-!-цж„én(!-é!дé—ц\\nъüéд-ц\\nq-!уъüéяn\\nц-n7éьё7цéуnь—уnîn„é-ц»!-цqу—zé—уц7`qвéц\"nя!д\\nn\\né\"яцдnвméb7—qé—»ц—уь!7ъqé—q\\nё!éсnün9!é(ябîé-цé(ябîц„é6ц9(цzé-q—»ц—уь!7цzé—q\\nёzé-q—»ц—уь!7цéсn)—7nq\\nбж\\'é;уné6-!îцéné7q»-ъüé0q--n—уzüménéьэ:7!„éné7qяq„éné—q\\nёq„éné»qьn7q»q—6n\\né(n—уn!-—у7q\\'à'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_ru = [u for u, _ in sorted(tokenz(encoded_test_ru).items(), key = lambda x: x[1], reverse = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ассоциируем буквы закодированного сообщения и оригинального по убыванию частоты - таким образом будет устроен декодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_ru = {encoded_ru[i] : letter_ru[i] for i in range(min(len(encoded_ru),len(letter_ru)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'чанна яарентна\\n, омтн тг иавьу гнавентльу рованос кыса локилозо, надтнаелип илас—е. айортгвов йраго.ж чсие идаилктсье иевыт шоуохт мрбз на мрбза, яахмап неидаилктсап иевып неидаилктса шоюисоевб\\ne цло янтза о седньу nенноилпуж о кsiст, о сере, о иевые, о декоседеияов моилотнилсеea'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original-> encoded-> decoded\n",
    "''.join([decoding_ru[encoded_test_ru[i]] for i in range(len(encoded_test_ru))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'«анна каренина», один из самых знаменитых романов льва толстого, начинается ставшей афоризмом фразой: «все счастливые семьи похожи друг на друга, каждая несчастливая семья несчастлива по-своему». это книга о вечных ценностях: о любви, о вере, о семье, о человеческом достоинстве.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "test_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну Анну, пробелы, запятые, и букву \"о\" мы смогли декодировать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.06481481481481481\n"
     ]
    }
   ],
   "source": [
    "true_n = 0\n",
    "for letter in letter_ru:\n",
    "    if encoding_ru[letter] in decoding_ru:\n",
    "        if decoding_ru[encoding_ru[letter]] == letter:\n",
    "            true_n += 1\n",
    "        \n",
    "print('accuracy: ', true_n/len(letter_ru))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закодированы только слова + опустим знаки препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words = tokenizer.tokenize(''.join(data_ru).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_ru_2 = [u for u, _ in sorted(tokenz(' '.join(words)).items(), key = lambda x: x[1], reverse = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_ru = np.random.permutation(letter_ru_2)\n",
    "\n",
    "encoding_ru = {letter_ru_2[i]:permutation_ru[i] for i in range(len(letter_ru_2))}\n",
    "encoding_ru[' '] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ru = ' '.join(tokenizer.tokenize(test_ru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_ru = ''.join([encoding_ru[test_ru[i]] for i in range(len(test_ru))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'аqqа заiкq0qа тв0q 0e êаm34 eqаmкq0834 iтmаqтâ côâа 8тcê8т т qаl0qак8êr ê8аâыкf алтi0emтm лiаeтf âêк êlаê8c0â3к êкmô0 ûт4тw0 вiй  qа вiй а заwваr qкêlаê8c0âаr êкmôr qкêlаê8c0âа ûт êâткmй a8т зq0 а т âкlq34 yкqqтê8r4 т cöиâ0 т âкiк т êкmôк т lкcтâкlкêзтm втê8т0qê8âк'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_ru = [u for u, _ in sorted(tokenz(encoded_test_ru).items(), key = lambda x: x[1], reverse = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_ru = {encoded_ru[i] : letter_ru_2[i] for i in range(min(len(encoded_ru),len(letter_ru_2)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'анна яарентна омтн тг иавьу гнавентльу рованос кыса локило о надтнаелип иласшеб ачортгвов чрагоб сие идаилктсье иевыт йоуожт мрз  на мрз а яажмап неидаилктсап иевып неидаилктса йо исоевз хло янт а о седньу eенноилпу о кюцст о сере о иевые о декоседеияов моилотнилсе'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original-> encoded-> decoded\n",
    "''.join([decoding_ru[encoded_test_ru[i]] for i in range(len(encoded_test_ru))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "true_n = 0\n",
    "for letter in letter_ru_2:\n",
    "    if encoding_ru[letter] in decoding_ru:\n",
    "        if decoding_ru[encoding_ru[letter]] == letter:\n",
    "            true_n += 1\n",
    "        \n",
    "print('accuracy: ', true_n/len(letter_ru))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(data_ru, num=1):\n",
    "    cv = CountVectorizer(data_ru, ngram_range=(num, num), analyzer='char')\n",
    "    count_vector = cv.fit_transform(data_ru)\n",
    "\n",
    "    #dict CountVectorizer\n",
    "    df = pd.DataFrame(cv.vocabulary_.items())\n",
    "    df.columns = ['char_val', 'ind']\n",
    "    cols = df.sort_values(by='ind').char_val.tolist()\n",
    "\n",
    "    #data\n",
    "    df_cv = pd.DataFrame(count_vector.todense())\n",
    "    df_cv.columns = cols\n",
    "    \n",
    "    dict_cnt = dict()\n",
    "    for col in df_cv.columns:\n",
    "        dict_cnt[col] = df_cv[col].sum()\n",
    "\n",
    "    df_cnt = pd.DataFrame(dict_cnt.items())\n",
    "    df_cnt.columns = ['char_val', 'sum']\n",
    "    df_cnt = df_cnt.sort_values(by='sum', ascending=False)\n",
    "    return df_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = make_dict(data_ru, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()\n",
    "df_new['real_char'] = orig.char_val\n",
    "df_new = df_new.reset_index()\n",
    "df_new['permutation_char'] = pd.Series(np.random.permutation(orig.char_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_char</th>\n",
       "      <th>permutation_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>о</td>\n",
       "      <td>\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>а</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  real_char permutation_char\n",
       "0                          s\n",
       "1         о               \\t\n",
       "2         а                )"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[['real_char', 'permutation_char']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dict = df_new.set_index('real_char')['permutation_char'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве\n",
      "\n",
      "\n",
      ")uu)sи)í»uёu)s\t(ёusёмsy)пhйsмu)п»uёphйsí\tп)u\tуs?ду)sp\t?yp\t2\tsu)0ёu)»pyбsyp)уq».s)е\tíёмп\tпsеí)м\t.sуy»sy0)yp?ёуh»sy»пдёsс\tй\t*ёs(íя2su)s(íя2)sи)*()бsu»y0)yp?ёу)бsy»пдбsu»y0)yp?ёу)sс\tsyу\t»пяsоp\tsиuё2)s\tsу»0uhйs8»uu\typбйs\ts?aауёs\tsу»í»s\tsy»пд»s\ts0»?\tу»0»yи\tпs(\typ\tёuypу»\n"
     ]
    }
   ],
   "source": [
    "print(test_ru)\n",
    "print('\\n')\n",
    "\n",
    "test_ru_coding = ''.join([encoding_dict[test_ru[i]] for i in range(len(test_ru))])\n",
    "\n",
    "print(test_ru_coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig2 = make_dict(data_ru, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "')uu)sи)í»uёu)s\\t(ёusёмsy)пhйsмu)п»uёphйsí\\tп)u\\tуs?ду)sp\\t?yp\\t2\\tsu)0ёu)»pyбsyp)уq».s)е\\tíёмп\\tпsеí)м\\t.sуy»sy0)yp?ёуh»sy»пдёsс\\tй\\t*ёs(íя2su)s(íя2)sи)*()бsu»y0)yp?ёу)бsy»пдбsu»y0)yp?ёу)sс\\tsyу\\t»пяsоp\\tsиuё2)s\\tsу»0uhйs8»uu\\typбйs\\ts?aауёs\\tsу»í»s\\tsy»пд»s\\ts0»?\\tу»0»yи\\tпs(\\typ\\tёuypу»'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ru_coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding = make_dict(list([test_ru_coding]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_new_dep = orig2.reset_index().merge(coding.reset_index(), left_index=True, right_index=True)\n",
    "decoding_dict = old_new_dep.set_index('char_val_y')['char_val_x'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве\n",
      "\n",
      "\n",
      "осели  пноены л ь ко ии  п влься инумуре — ссела рал но,ази ладеь ко гкнал нсосколк осон— одлоарет д ппе оиса,о  оаяег, наи руня ии авв х аме  со и,виакслесприет ойиманредавеол мкилеомину мапря ри кст сов беро гоневоасхост с кторабыроотва а у лсьропо. ли ттинаи  ппо. ли тм  пноенобитвсоре натакаов беро гонево доре  с кторамие натакаов беро гонево д потва,  сны.\n",
      "тртотетьe  з о, ноемкоилм  п в, я а нин ивал недчть елонзао ейдо н в, ломеылог чро в, я а атл ст в,  с кторамост в,  эй  еди— а ний кас жеол мпочезао  онн ивыо ю а \n"
     ]
    }
   ],
   "source": [
    "print(test_ru)\n",
    "print('\\n')\n",
    "# print(test_ru_coding)\n",
    "# print('\\n')\n",
    "\n",
    "test_ru_decoding = ''.join([decoding_dict[test_ru_coding[i:i+2]] for i in range(len(test_ru_coding)-1)])\n",
    "print(test_ru_decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "accuracy:  0.06037735849056604\n"
     ]
    }
   ],
   "source": [
    "print(len(test_ru_decoding) == len(test_ru))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(test_ru)):\n",
    "    if test_ru[i] == test_ru_decoding[i]:\n",
    "        count += 1\n",
    "\n",
    "print('accuracy: ', count/len(test_ru))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea\n",
    "\n",
    "1) Start by picking up a random current state.\\\n",
    "2) Create a proposal for a new state by swapping two random letters in the current state.\\\n",
    "3) Use a Scoring Function which calculates the score of the current state Score_C and the proposed State Score_P.\\\n",
    "4) If the score of the proposed state is more than the current state, Move to Proposed State.\\\n",
    "5) Else flip a coin which has a probability of Heads Score_P/Score_C. If it comes heads move to the proposed State.\\\n",
    "6) Repeat from 2nd.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "import random\n",
    " \n",
    "def create_cipher_dict(cipher):\n",
    "    cipher_dict = {}\n",
    "    alphabet_list = list(string.ascii_uppercase)\n",
    "    for i in range(len(cipher)):\n",
    "        cipher_dict[alphabet_list[i]] = cipher[i]\n",
    "    return cipher_dict\n",
    "\n",
    "\n",
    "def apply_cipher_on_text(text,cipher):\n",
    "    cipher_dict = create_cipher_dict(cipher) \n",
    "    text = list(text)\n",
    "    newtext = \"\"\n",
    "    for elem in text:\n",
    "        if elem.upper() in cipher_dict:\n",
    "            newtext+=cipher_dict[elem.upper()]\n",
    "        else:\n",
    "            newtext+=\" \"\n",
    "    return newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scoring_params_dict(longtext_path):\n",
    "    scoring_params = {}\n",
    "    alphabet_list = list(string.ascii_uppercase)\n",
    "    with open(longtext_path) as fp:\n",
    "        for line in fp:\n",
    "            data = list(line.strip())\n",
    "            for i in range(len(data)-1):\n",
    "                alpha_i = data[i].upper()\n",
    "                alpha_j = data[i+1].upper()\n",
    "                if alpha_i not in alphabet_list and alpha_i != \" \":\n",
    "                    alpha_i = \" \"\n",
    "                if alpha_j not in alphabet_list and alpha_j != \" \":\n",
    "                    alpha_j = \" \"\n",
    "                key = alpha_i+alpha_j\n",
    "                if key in scoring_params:\n",
    "                    scoring_params[key]+=1\n",
    "                else:\n",
    "                    scoring_params[key]=1\n",
    "    return scoring_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_params_on_cipher(text):\n",
    "    scoring_params = {}\n",
    "    alphabet_list = list(string.ascii_uppercase)\n",
    "    data = list(text.strip())\n",
    "    for i in range(len(data)-1):\n",
    "        alpha_i =data[i].upper()\n",
    "        alpha_j = data[i+1].upper()\n",
    "        if alpha_i not in alphabet_list and alpha_i != \" \":\n",
    "            alpha_i = \" \"\n",
    "        if alpha_j not in alphabet_list and alpha_j != \" \":\n",
    "            alpha_j = \" \"\n",
    "        key = alpha_i+alpha_j\n",
    "        if key in scoring_params:\n",
    "            scoring_params[key]+=1\n",
    "        else:\n",
    "            scoring_params[key]=1\n",
    "    return scoring_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cipher_score(text,cipher,scoring_params):\n",
    "    cipher_dict = create_cipher_dict(cipher)\n",
    "    decrypted_text = apply_cipher_on_text(text,cipher)\n",
    "    scored_f = score_params_on_cipher(decrypted_text)\n",
    "    cipher_score = 0\n",
    "    for k,v in scored_f.items():\n",
    "        if k in scoring_params:\n",
    "            cipher_score += v*math.log(scoring_params[k])\n",
    "    return cipher_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cipher(cipher):\n",
    "    pos1 = random.randint(0, len(list(cipher))-1)\n",
    "    pos2 = random.randint(0, len(list(cipher))-1)\n",
    "    if pos1 == pos2:\n",
    "        return generate_cipher(cipher)\n",
    "    else:\n",
    "        cipher = list(cipher)\n",
    "        pos1_alpha = cipher[pos1]\n",
    "        pos2_alpha = cipher[pos2]\n",
    "        cipher[pos1] = pos2_alpha\n",
    "        cipher[pos2] = pos1_alpha\n",
    "        return \"\".join(cipher)\n",
    "\n",
    "\n",
    "def random_coin(p):\n",
    "    unif = random.uniform(0,1)\n",
    "    if unif>=p:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC_decrypt(n_iter,cipher_text,scoring_params):\n",
    "    current_cipher = string.ascii_uppercase # Generate a random cipher to start\n",
    "    state_keeper = set()\n",
    "    best_state = ''\n",
    "    score = 0\n",
    "    for i in range(n_iter):\n",
    "        state_keeper.add(current_cipher)\n",
    "        proposed_cipher = generate_cipher(current_cipher)\n",
    "        score_current_cipher = get_cipher_score(cipher_text,current_cipher,scoring_params)\n",
    "        score_proposed_cipher = get_cipher_score(cipher_text,proposed_cipher,scoring_params)\n",
    "        acceptance_probability = min(1,math.exp(score_proposed_cipher-score_current_cipher))\n",
    "        if score_current_cipher>score:\n",
    "            best_state = current_cipher\n",
    "        if random_coin(acceptance_probability):\n",
    "            current_cipher = proposed_cipher\n",
    "        if i%500==0:\n",
    "            print(\"iter\",i,\":\",apply_cipher_on_text(cipher_text,current_cipher)[0:99])\n",
    "    return state_keeper,best_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_params = create_scoring_params_dict('./data_hw4/WarAndPeaceEng.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text = 'English texts for beginners to practice reading and comprehension online and for free. Practicing your comprehension of written English will both improve your vocabulary and understanding of grammar and word order. The texts below are designed to help you develop while giving you an instant evaluation of your progress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_key = ''.join(np.random.permutation(list(string.ascii_uppercase)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cipher_text = apply_cipher_on_text(plain_text,en_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_key = ''.join(np.random.permutation(list(string.ascii_uppercase)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text To Decode: CXYMSFT DCLDF BEW ACYSXXCWF DE IWONDSNC WCOZSXY OXZ NEGIWCTCXFSEX EXMSXC OXZ BEW BWCC  IWONDSNSXY PEVW NEGIWCTCXFSEX EB RWSDDCX CXYMSFT RSMM AEDT SGIWEJC PEVW JENOAVMOWP OXZ VXZCWFDOXZSXY EB YWOGGOW OXZ REWZ EWZCW  DTC DCLDF ACMER OWC ZCFSYXCZ DE TCMI PEV ZCJCMEI RTSMC YSJSXY PEV OX SXFDOXD CJOMVODSEX EB PEVW IWEYWCFF\n",
      "\n",
      "\n",
      "iter 0 : CXYMSFT DCLDF BEU ACYSXXCUF DE IUONDSNC UCOZSXY OXZ NEGIUCTCXFSEX EXMSXC OXZ BEU BUCC  IUONDSNSXY P\n",
      "iter 500 : ENDLTCR IEYIC VOS HEDTNNESC IO USAFITFE SEAGTND ANG FOBUSERENCTON ONLTNE ANG VOS VSEE  USAFITFTND M\n",
      "iter 1000 : ENGLIFR TEXTF WOS BEGINNESF TO USACTICE SEADING AND COKUSERENFION ONLINE AND WOS WSEE  USACTICING H\n",
      "iter 1500 : ENGLIFR TEXTF MOS YEGINNESF TO USACTICE SEADING AND COBUSERENFION ONLINE AND MOS MSEE  USACTICING H\n",
      "iter 2000 : ENGLICR TEXTC MOS YEGINNESC TO USAFTIFE SEADING AND FOBUSERENCION ONLINE AND MOS MSEE  USAFTIFING H\n",
      "iter 2500 : ENGLICR TEXTC FOS BEGINNESC TO USAPTIPE SEADING AND POMUSERENCION ONLINE AND FOS FSEE  USAPTIPING H\n",
      "iter 3000 : ENGLICH TEXTC FOS BEGINNESC TO USAPTIPE SEADING AND POMUSEHENCION ONLINE AND FOS FSEE  USAPTIPING Y\n",
      "iter 3500 : ENGLICH TEXTC FOS BEGINNESC TO USAPTIPE SEADING AND POMUSEHENCION ONLINE AND FOS FSEE  USAPTIPING Y\n",
      "iter 4000 : ENGLICH TEXTC FOS BEGINNESC TO USAPTIPE SEADING AND POMUSEHENCION ONLINE AND FOS FSEE  USAPTIPING Y\n",
      "iter 4500 : ENGLICH TEXTC FOR BEGINNERC TO URASTISE READING AND SOPUREHENCION ONLINE AND FOR FREE  URASTISING Y\n",
      "iter 5000 : ENGLISH TEXTS FOR BEGINNERS TO URACTICE READING AND COMUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 5500 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 6000 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 6500 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 7000 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 7500 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 8000 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 8500 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 9000 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "iter 9500 : ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING Y\n",
      "\n",
      "\n",
      "Decoded Text: ENGLISH TEXTS FOR MEGINNERS TO URACTICE READING AND COBUREHENSION ONLINE AND FOR FREE  URACTICING YOPR COBUREHENSION OF WRITTEN ENGLISH WILL MOTH IBUROVE YOPR VOCAMPLARY AND PNDERSTANDING OF GRABBAR AND WORD ORDER  THE TEXTS MELOW ARE DESIGNED TO HELU YOP DEVELOU WHILE GIVING YOP AN INSTANT EVALPATION OF YOPR UROGRESS\n",
      "\n",
      "\n",
      "MCMC KEY FOUND: MFETOSBQUVZXLCAYKWIHJPRNGD\n",
      "ACTUAL DECRYPTION KEY: WNOSTHPQCLGXRFABVUEZYIKMJD\n"
     ]
    }
   ],
   "source": [
    "print(\"Text To Decode:\", cipher_text)\n",
    "print(\"\\n\")\n",
    "states,best_state = MCMC_decrypt(10000,cipher_text,scoring_params)\n",
    "print(\"\\n\")\n",
    "print(\"Decoded Text:\",apply_cipher_on_text(cipher_text,best_state))\n",
    "print(\"\\n\")\n",
    "print(\"MCMC KEY FOUND:\",best_state)\n",
    "print(\"ACTUAL DECRYPTION KEY:\",dec_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
